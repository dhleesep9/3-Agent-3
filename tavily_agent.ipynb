{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade langchain langchain-community langchain-openai langchain-core langchainhub tavily-python python-dotenv -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 시스템 환경 변수에서 Tavily API 키를 로드했습니다.\n",
            "✅ 환경 설정 완료\n",
            "Tavily API Key: ✅ 설정됨\n",
            "OpenAI API Key: ✅ 설정됨\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain import hub\n",
        "\n",
        "# 환경 변수 로드 (.env 파일이 있다면)\n",
        "load_dotenv()\n",
        "\n",
        "# Windows에서 setx로 설정한 환경 변수는 새 프로세스에서만 적용됩니다\n",
        "# Jupyter Notebook이 이미 실행 중이었다면 아래 코드로 다시 로드\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        ['powershell', '-Command', '[System.Environment]::GetEnvironmentVariable(\"TAVILY_API_KEY\", \"User\")'],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    if result.stdout.strip():\n",
        "        os.environ[\"TAVILY_API_KEY\"] = result.stdout.strip()\n",
        "        print(\"✅ 시스템 환경 변수에서 Tavily API 키를 로드했습니다.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# API 키 확인\n",
        "tavily_api_key = os.getenv(\"TAVILY_API_KEY\", \"\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "\n",
        "print(\"✅ 환경 설정 완료\")\n",
        "print(f\"Tavily API Key: {'✅ 설정됨' if tavily_api_key else '❌ 미설정'}\")\n",
        "print(f\"OpenAI API Key: {'✅ 설정됨' if openai_api_key else '❌ 미설정'}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tavily Tool 초기화 완료\n"
          ]
        }
      ],
      "source": [
        "# Tavily 검색 Tool 생성\n",
        "tavily_tool = TavilySearchResults(\n",
        "    api_key=os.getenv(\"TAVILY_API_KEY\", \"\"),\n",
        "    max_results=5\n",
        ")\n",
        "\n",
        "print(\"✅ Tavily Tool 초기화 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
            "Please use the `langsmith sdk` instead:\n",
            "  pip install langsmith\n",
            "Use the `pull_prompt` method.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ AgentExecutor 생성 완료\n"
          ]
        }
      ],
      "source": [
        "# LLM 초기화\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    api_key=openai_api_key,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Tools\n",
        "tools = [tavily_tool]\n",
        "\n",
        "# Agent 프롬프트 가져오기\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Agent 생성\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# AgentExecutor 생성\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, \n",
        "    tools=tools, \n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"✅ AgentExecutor 생성 완료\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "질문: 내일 서울 비 와?\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.beta'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m----> 9\u001b[0m result1 \u001b[38;5;241m=\u001b[39m agent_executor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: question1})\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최종 답변:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36minvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m, in \u001b[0;36m_call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1140\u001b[0m, in \u001b[0;36m_take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:1166\u001b[0m, in \u001b[0;36m_iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain\\agents\\agent.py:514\u001b[0m, in \u001b[0;36mplan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2875\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2789\u001b[0m class RunnableSequence(RunnableSerializable[Input, Output]):\n\u001b[0;32m   2790\u001b[0m     \"\"\"Sequence of `Runnable` objects, where the output of one is the input of the next.\n\u001b[0;32m   2791\u001b[0m \n\u001b[0;32m   2792\u001b[0m     **`RunnableSequence`** is the most important composition operator in LangChain\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2870\u001b[0m         ```\n\u001b[0;32m   2871\u001b[0m     \"\"\"\n\u001b[0;32m   2873\u001b[0m     # The steps are broken into first, middle and last, solely for type checking\n\u001b[0;32m   2874\u001b[0m     # purposes. It allows specifying the `Input` on the first type, the `Output` of\n\u001b[1;32m-> 2875\u001b[0m     # the last type.\n\u001b[0;32m   2876\u001b[0m     first: Runnable[Input, Any]\n\u001b[0;32m   2877\u001b[0m     \"\"\"The first `Runnable` in the sequence.\"\"\"\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2862\u001b[0m, in \u001b[0;36mtransform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRunnableSequence\u001b[39;00m(RunnableSerializable[Input, Output]):\n\u001b[0;32m   2790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sequence of `Runnable` objects, where the output of one is the input of the next.\u001b[39;00m\n\u001b[0;32m   2791\u001b[0m \n\u001b[0;32m   2792\u001b[0m \u001b[38;5;124;03m    **`RunnableSequence`** is the most important composition operator in LangChain\u001b[39;00m\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;124;03m    as it is used in virtually every chain.\u001b[39;00m\n\u001b[0;32m   2794\u001b[0m \n\u001b[0;32m   2795\u001b[0m \u001b[38;5;124;03m    A `RunnableSequence` can be instantiated directly or more commonly by using the\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;124;03m    `|` operator where either the left or right operands (or both) must be a\u001b[39;00m\n\u001b[0;32m   2797\u001b[0m \u001b[38;5;124;03m    `Runnable`.\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m \n\u001b[0;32m   2799\u001b[0m \u001b[38;5;124;03m    Any `RunnableSequence` automatically supports sync, async, batch.\u001b[39;00m\n\u001b[0;32m   2800\u001b[0m \n\u001b[0;32m   2801\u001b[0m \u001b[38;5;124;03m    The default implementations of `batch` and `abatch` utilize threadpools and\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[38;5;124;03m    asyncio gather and will be faster than naive invocation of `invoke` or `ainvoke`\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \u001b[38;5;124;03m    for IO bound `Runnable`s.\u001b[39;00m\n\u001b[0;32m   2804\u001b[0m \n\u001b[0;32m   2805\u001b[0m \u001b[38;5;124;03m    Batching is implemented by invoking the batch method on each component of the\u001b[39;00m\n\u001b[0;32m   2806\u001b[0m \u001b[38;5;124;03m    `RunnableSequence` in order.\u001b[39;00m\n\u001b[0;32m   2807\u001b[0m \n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    A `RunnableSequence` preserves the streaming properties of its components, so if\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    all components of the sequence implement a `transform` method -- which\u001b[39;00m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;124;03m    is the method that implements the logic to map a streaming input to a streaming\u001b[39;00m\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;124;03m    output -- then the sequence will be able to stream input to output!\u001b[39;00m\n\u001b[0;32m   2812\u001b[0m \n\u001b[0;32m   2813\u001b[0m \u001b[38;5;124;03m    If any component of the sequence does not implement transform then the\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;124;03m    streaming will only begin after this component is run. If there are\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \u001b[38;5;124;03m    multiple blocking components, streaming begins after the last one.\u001b[39;00m\n\u001b[0;32m   2816\u001b[0m \n\u001b[0;32m   2817\u001b[0m \u001b[38;5;124;03m    !!! note\u001b[39;00m\n\u001b[0;32m   2818\u001b[0m \u001b[38;5;124;03m        `RunnableLambdas` do not support `transform` by default! So if you need to\u001b[39;00m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;124;03m        use a `RunnableLambdas` be careful about where you place them in a\u001b[39;00m\n\u001b[0;32m   2820\u001b[0m \u001b[38;5;124;03m        `RunnableSequence` (if you need to use the `stream`/`astream` methods).\u001b[39;00m\n\u001b[0;32m   2821\u001b[0m \n\u001b[0;32m   2822\u001b[0m \u001b[38;5;124;03m        If you need arbitrary logic and need streaming, you can subclass\u001b[39;00m\n\u001b[0;32m   2823\u001b[0m \u001b[38;5;124;03m        Runnable, and implement `transform` for whatever logic you need.\u001b[39;00m\n\u001b[0;32m   2824\u001b[0m \n\u001b[0;32m   2825\u001b[0m \u001b[38;5;124;03m    Here is a simple example that uses simple functions to illustrate the use of\u001b[39;00m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;124;03m    `RunnableSequence`:\u001b[39;00m\n\u001b[0;32m   2827\u001b[0m \n\u001b[0;32m   2828\u001b[0m \u001b[38;5;124;03m        ```python\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;124;03m        from langchain_core.runnables import RunnableLambda\u001b[39;00m\n\u001b[0;32m   2830\u001b[0m \n\u001b[0;32m   2831\u001b[0m \n\u001b[0;32m   2832\u001b[0m \u001b[38;5;124;03m        def add_one(x: int) -> int:\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m \u001b[38;5;124;03m            return x + 1\u001b[39;00m\n\u001b[0;32m   2834\u001b[0m \n\u001b[0;32m   2835\u001b[0m \n\u001b[0;32m   2836\u001b[0m \u001b[38;5;124;03m        def mul_two(x: int) -> int:\u001b[39;00m\n\u001b[0;32m   2837\u001b[0m \u001b[38;5;124;03m            return x * 2\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \n\u001b[0;32m   2839\u001b[0m \n\u001b[0;32m   2840\u001b[0m \u001b[38;5;124;03m        runnable_1 = RunnableLambda(add_one)\u001b[39;00m\n\u001b[0;32m   2841\u001b[0m \u001b[38;5;124;03m        runnable_2 = RunnableLambda(mul_two)\u001b[39;00m\n\u001b[0;32m   2842\u001b[0m \u001b[38;5;124;03m        sequence = runnable_1 | runnable_2\u001b[39;00m\n\u001b[0;32m   2843\u001b[0m \u001b[38;5;124;03m        # Or equivalently:\u001b[39;00m\n\u001b[0;32m   2844\u001b[0m \u001b[38;5;124;03m        # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\u001b[39;00m\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;124;03m        sequence.invoke(1)\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \u001b[38;5;124;03m        await sequence.ainvoke(1)\u001b[39;00m\n\u001b[0;32m   2847\u001b[0m \n\u001b[0;32m   2848\u001b[0m \u001b[38;5;124;03m        sequence.batch([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   2849\u001b[0m \u001b[38;5;124;03m        await sequence.abatch([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   2850\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m   2851\u001b[0m \n\u001b[0;32m   2852\u001b[0m \u001b[38;5;124;03m    Here's an example that uses streams JSON output generated by an LLM:\u001b[39;00m\n\u001b[0;32m   2853\u001b[0m \n\u001b[0;32m   2854\u001b[0m \u001b[38;5;124;03m        ```python\u001b[39;00m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;124;03m        from langchain_core.output_parsers.json import SimpleJsonOutputParser\u001b[39;00m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;124;03m        from langchain_openai import ChatOpenAI\u001b[39;00m\n\u001b[0;32m   2857\u001b[0m \n\u001b[0;32m   2858\u001b[0m \u001b[38;5;124;03m        prompt = PromptTemplate.from_template(\u001b[39;00m\n\u001b[0;32m   2859\u001b[0m \u001b[38;5;124;03m            \"In JSON format, give me a list of {topic} and their \"\u001b[39;00m\n\u001b[0;32m   2860\u001b[0m \u001b[38;5;124;03m            \"corresponding names in French, Spanish and in a \"\u001b[39;00m\n\u001b[0;32m   2861\u001b[0m \u001b[38;5;124;03m            \"Cat Language.\"\u001b[39;00m\n\u001b[1;32m-> 2862\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[0;32m   2863\u001b[0m \n\u001b[0;32m   2864\u001b[0m \u001b[38;5;124;03m        model = ChatOpenAI()\u001b[39;00m\n\u001b[0;32m   2865\u001b[0m \u001b[38;5;124;03m        chain = prompt | model | SimpleJsonOutputParser()\u001b[39;00m\n\u001b[0;32m   2866\u001b[0m \n\u001b[0;32m   2867\u001b[0m \u001b[38;5;124;03m        async for chunk in chain.astream({\"topic\": \"colors\"}):\u001b[39;00m\n\u001b[0;32m   2868\u001b[0m \u001b[38;5;124;03m            print(\"-\")  # noqa: T201\u001b[39;00m\n\u001b[0;32m   2869\u001b[0m \u001b[38;5;124;03m            print(chunk, sep=\"\", flush=True)  # noqa: T201\u001b[39;00m\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m   2871\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2873\u001b[0m     \u001b[38;5;66;03m# The steps are broken into first, middle and last, solely for type checking\u001b[39;00m\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;66;03m# purposes. It allows specifying the `Input` on the first type, the `Output` of\u001b[39;00m\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;66;03m# the last type.\u001b[39;00m\n\u001b[0;32m   2876\u001b[0m     first: Runnable[Input, Any]\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1881\u001b[0m, in \u001b[0;36m_transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_retry\u001b[39m(\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     stop_after_attempt: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   1857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[Input, Output]:\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new `Runnable` that retries the original `Runnable` on exceptions.\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;124;03m        retry_if_exception_type: A tuple of exception types to retry on.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;124;03m        wait_exponential_jitter: Whether to add jitter to the wait\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m \u001b[38;5;124;03m            time between retries.\u001b[39;00m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;124;03m        stop_after_attempt: The maximum number of attempts to make before\u001b[39;00m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;124;03m            giving up.\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;124;03m        exponential_jitter_params: Parameters for\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;124;03m            `tenacity.wait_exponential_jitter`. Namely: `initial`, `max`,\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;124;03m            `exp_base`, and `jitter` (all `float` values).\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \n\u001b[0;32m   1870\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;124;03m        A new `Runnable` that retries the original `Runnable` on exceptions.\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m \n\u001b[0;32m   1873\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m \u001b[38;5;124;03m        ```python\u001b[39;00m\n\u001b[0;32m   1875\u001b[0m \u001b[38;5;124;03m        from langchain_core.runnables import RunnableLambda\u001b[39;00m\n\u001b[0;32m   1876\u001b[0m \n\u001b[0;32m   1877\u001b[0m \u001b[38;5;124;03m        count = 0\u001b[39;00m\n\u001b[0;32m   1878\u001b[0m \n\u001b[0;32m   1879\u001b[0m \n\u001b[0;32m   1880\u001b[0m \u001b[38;5;124;03m        def _lambda(x: int) -> None:\u001b[39;00m\n\u001b[1;32m-> 1881\u001b[0m \u001b[38;5;124;03m            global count\u001b[39;00m\n\u001b[0;32m   1882\u001b[0m \u001b[38;5;124;03m            count = count + 1\u001b[39;00m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m            if x == 1:\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m                raise ValueError(\"x is 1\")\u001b[39;00m\n\u001b[0;32m   1885\u001b[0m \u001b[38;5;124;03m            else:\u001b[39;00m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;124;03m                pass\u001b[39;00m\n\u001b[0;32m   1887\u001b[0m \n\u001b[0;32m   1888\u001b[0m \n\u001b[0;32m   1889\u001b[0m \u001b[38;5;124;03m        runnable = RunnableLambda(_lambda)\u001b[39;00m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;124;03m        try:\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;124;03m            runnable.with_retry(\u001b[39;00m\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;124;03m                stop_after_attempt=2,\u001b[39;00m\n\u001b[0;32m   1893\u001b[0m \u001b[38;5;124;03m                retry_if_exception_type=(ValueError,),\u001b[39;00m\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;124;03m            ).invoke(1)\u001b[39;00m\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;124;03m        except ValueError:\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m \u001b[38;5;124;03m            pass\u001b[39;00m\n\u001b[0;32m   1897\u001b[0m \n\u001b[0;32m   1898\u001b[0m \u001b[38;5;124;03m        assert count == 2\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1901\u001b[0m     \u001b[38;5;66;03m# Import locally to prevent circular import\u001b[39;00m\n\u001b[0;32m   1902\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableRetry  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\dohom\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2808\u001b[0m, in \u001b[0;36m_transform\u001b[1;34m(self, input, run_manager, config)\u001b[0m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRunnableSequence\u001b[39;00m(RunnableSerializable[Input, Output]):\n\u001b[0;32m   2790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sequence of `Runnable` objects, where the output of one is the input of the next.\u001b[39;00m\n\u001b[0;32m   2791\u001b[0m \n\u001b[0;32m   2792\u001b[0m \u001b[38;5;124;03m    **`RunnableSequence`** is the most important composition operator in LangChain\u001b[39;00m\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;124;03m    as it is used in virtually every chain.\u001b[39;00m\n\u001b[0;32m   2794\u001b[0m \n\u001b[0;32m   2795\u001b[0m \u001b[38;5;124;03m    A `RunnableSequence` can be instantiated directly or more commonly by using the\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;124;03m    `|` operator where either the left or right operands (or both) must be a\u001b[39;00m\n\u001b[0;32m   2797\u001b[0m \u001b[38;5;124;03m    `Runnable`.\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m \n\u001b[0;32m   2799\u001b[0m \u001b[38;5;124;03m    Any `RunnableSequence` automatically supports sync, async, batch.\u001b[39;00m\n\u001b[0;32m   2800\u001b[0m \n\u001b[0;32m   2801\u001b[0m \u001b[38;5;124;03m    The default implementations of `batch` and `abatch` utilize threadpools and\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[38;5;124;03m    asyncio gather and will be faster than naive invocation of `invoke` or `ainvoke`\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \u001b[38;5;124;03m    for IO bound `Runnable`s.\u001b[39;00m\n\u001b[0;32m   2804\u001b[0m \n\u001b[0;32m   2805\u001b[0m \u001b[38;5;124;03m    Batching is implemented by invoking the batch method on each component of the\u001b[39;00m\n\u001b[0;32m   2806\u001b[0m \u001b[38;5;124;03m    `RunnableSequence` in order.\u001b[39;00m\n\u001b[0;32m   2807\u001b[0m \n\u001b[1;32m-> 2808\u001b[0m \u001b[38;5;124;03m    A `RunnableSequence` preserves the streaming properties of its components, so if\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    all components of the sequence implement a `transform` method -- which\u001b[39;00m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;124;03m    is the method that implements the logic to map a streaming input to a streaming\u001b[39;00m\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;124;03m    output -- then the sequence will be able to stream input to output!\u001b[39;00m\n\u001b[0;32m   2812\u001b[0m \n\u001b[0;32m   2813\u001b[0m \u001b[38;5;124;03m    If any component of the sequence does not implement transform then the\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;124;03m    streaming will only begin after this component is run. If there are\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \u001b[38;5;124;03m    multiple blocking components, streaming begins after the last one.\u001b[39;00m\n\u001b[0;32m   2816\u001b[0m \n\u001b[0;32m   2817\u001b[0m \u001b[38;5;124;03m    !!! note\u001b[39;00m\n\u001b[0;32m   2818\u001b[0m \u001b[38;5;124;03m        `RunnableLambdas` do not support `transform` by default! So if you need to\u001b[39;00m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;124;03m        use a `RunnableLambdas` be careful about where you place them in a\u001b[39;00m\n\u001b[0;32m   2820\u001b[0m \u001b[38;5;124;03m        `RunnableSequence` (if you need to use the `stream`/`astream` methods).\u001b[39;00m\n\u001b[0;32m   2821\u001b[0m \n\u001b[0;32m   2822\u001b[0m \u001b[38;5;124;03m        If you need arbitrary logic and need streaming, you can subclass\u001b[39;00m\n\u001b[0;32m   2823\u001b[0m \u001b[38;5;124;03m        Runnable, and implement `transform` for whatever logic you need.\u001b[39;00m\n\u001b[0;32m   2824\u001b[0m \n\u001b[0;32m   2825\u001b[0m \u001b[38;5;124;03m    Here is a simple example that uses simple functions to illustrate the use of\u001b[39;00m\n\u001b[0;32m   2826\u001b[0m \u001b[38;5;124;03m    `RunnableSequence`:\u001b[39;00m\n\u001b[0;32m   2827\u001b[0m \n\u001b[0;32m   2828\u001b[0m \u001b[38;5;124;03m        ```python\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;124;03m        from langchain_core.runnables import RunnableLambda\u001b[39;00m\n\u001b[0;32m   2830\u001b[0m \n\u001b[0;32m   2831\u001b[0m \n\u001b[0;32m   2832\u001b[0m \u001b[38;5;124;03m        def add_one(x: int) -> int:\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m \u001b[38;5;124;03m            return x + 1\u001b[39;00m\n\u001b[0;32m   2834\u001b[0m \n\u001b[0;32m   2835\u001b[0m \n\u001b[0;32m   2836\u001b[0m \u001b[38;5;124;03m        def mul_two(x: int) -> int:\u001b[39;00m\n\u001b[0;32m   2837\u001b[0m \u001b[38;5;124;03m            return x * 2\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \n\u001b[0;32m   2839\u001b[0m \n\u001b[0;32m   2840\u001b[0m \u001b[38;5;124;03m        runnable_1 = RunnableLambda(add_one)\u001b[39;00m\n\u001b[0;32m   2841\u001b[0m \u001b[38;5;124;03m        runnable_2 = RunnableLambda(mul_two)\u001b[39;00m\n\u001b[0;32m   2842\u001b[0m \u001b[38;5;124;03m        sequence = runnable_1 | runnable_2\u001b[39;00m\n\u001b[0;32m   2843\u001b[0m \u001b[38;5;124;03m        # Or equivalently:\u001b[39;00m\n\u001b[0;32m   2844\u001b[0m \u001b[38;5;124;03m        # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\u001b[39;00m\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;124;03m        sequence.invoke(1)\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \u001b[38;5;124;03m        await sequence.ainvoke(1)\u001b[39;00m\n\u001b[0;32m   2847\u001b[0m \n\u001b[0;32m   2848\u001b[0m \u001b[38;5;124;03m        sequence.batch([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   2849\u001b[0m \u001b[38;5;124;03m        await sequence.abatch([1, 2, 3])\u001b[39;00m\n\u001b[0;32m   2850\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m   2851\u001b[0m \n\u001b[0;32m   2852\u001b[0m \u001b[38;5;124;03m    Here's an example that uses streams JSON output generated by an LLM:\u001b[39;00m\n\u001b[0;32m   2853\u001b[0m \n\u001b[0;32m   2854\u001b[0m \u001b[38;5;124;03m        ```python\u001b[39;00m\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;124;03m        from langchain_core.output_parsers.json import SimpleJsonOutputParser\u001b[39;00m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;124;03m        from langchain_openai import ChatOpenAI\u001b[39;00m\n\u001b[0;32m   2857\u001b[0m \n\u001b[0;32m   2858\u001b[0m \u001b[38;5;124;03m        prompt = PromptTemplate.from_template(\u001b[39;00m\n\u001b[0;32m   2859\u001b[0m \u001b[38;5;124;03m            \"In JSON format, give me a list of {topic} and their \"\u001b[39;00m\n\u001b[0;32m   2860\u001b[0m \u001b[38;5;124;03m            \"corresponding names in French, Spanish and in a \"\u001b[39;00m\n\u001b[0;32m   2861\u001b[0m \u001b[38;5;124;03m            \"Cat Language.\"\u001b[39;00m\n\u001b[0;32m   2862\u001b[0m \u001b[38;5;124;03m        )\u001b[39;00m\n\u001b[0;32m   2863\u001b[0m \n\u001b[0;32m   2864\u001b[0m \u001b[38;5;124;03m        model = ChatOpenAI()\u001b[39;00m\n\u001b[0;32m   2865\u001b[0m \u001b[38;5;124;03m        chain = prompt | model | SimpleJsonOutputParser()\u001b[39;00m\n\u001b[0;32m   2866\u001b[0m \n\u001b[0;32m   2867\u001b[0m \u001b[38;5;124;03m        async for chunk in chain.astream({\"topic\": \"colors\"}):\u001b[39;00m\n\u001b[0;32m   2868\u001b[0m \u001b[38;5;124;03m            print(\"-\")  # noqa: T201\u001b[39;00m\n\u001b[0;32m   2869\u001b[0m \u001b[38;5;124;03m            print(chunk, sep=\"\", flush=True)  # noqa: T201\u001b[39;00m\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;124;03m        ```\u001b[39;00m\n\u001b[0;32m   2871\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2873\u001b[0m     \u001b[38;5;66;03m# The steps are broken into first, middle and last, solely for type checking\u001b[39;00m\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;66;03m# purposes. It allows specifying the `Input` on the first type, the `Output` of\u001b[39;00m\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;66;03m# the last type.\u001b[39;00m\n\u001b[0;32m   2876\u001b[0m     first: Runnable[Input, Any]\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.beta'"
          ]
        }
      ],
      "source": [
        "# 질문 1: 날씨 정보\n",
        "question1 = \"내일 서울 비 와?\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"질문: {question1}\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "result1 = agent_executor.invoke({\"input\": question1})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"최종 답변:\")\n",
        "print(\"=\" * 60)\n",
        "print(result1[\"output\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 질문 2: 맛집 추천\n",
        "question2 = \"강남역 최신 맛집 3개 추천해줘\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"질문: {question2}\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "result2 = agent_executor.invoke({\"input\": question2})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"최종 답변:\")\n",
        "print(\"=\" * 60)\n",
        "print(result2[\"output\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 질문 3: 뉴스 요약\n",
        "question3 = \"NVIDIA 최근 뉴스 요약해줘\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"질문: {question3}\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "result3 = agent_executor.invoke({\"input\": question3})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"최종 답변:\")\n",
        "print(\"=\" * 60)\n",
        "print(result3[\"output\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
